# -*- coding: utf-8 -*-
"""Final FRDA Project Streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1urFsgQkHaonmo--iWFBJByRr0YuEC6yz
"""

import numpy as np
import pandas as pd
import streamlit as st

# --- Page management ---
if "page" not in st.session_state:
    st.session_state["page"] = "home"

# --- Home Page (File Upload + EDA) ---
if st.session_state["page"] == "home":
    st.title("üìä Fraud Detection Data Explorer")

    # Sidebar file uploader
    st.sidebar.header("Upload your file")
    uploaded_file = st.sidebar.file_uploader("Choose a CSV or Excel file", type=["csv", "xlsx", "xls"])

    if uploaded_file is not None:
        # Detect file type and read accordingly
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file, engine="python")
            st.success("CSV file uploaded successfully ‚úÖ")
        else:
            df = pd.read_excel(uploaded_file)
            st.success("Excel file uploaded successfully ‚úÖ")

        # Show Head
        st.subheader("Dataset Preview (first 5 rows)")
        st.dataframe(df.head())

        # Shape
        st.subheader("Dataset Shape")
        st.write(f"Rows: {df.shape[0]}, Columns: {df.shape[1]}")

        # Info
        import io
        st.subheader("Dataset Info")
        buffer = io.StringIO()       # create a string buffer
        df.info(buf=buffer)          # write info to buffer
        info_str = buffer.getvalue() # get string from buffer
        st.text(info_str)


        drop_cols = ['Transaction_ID', 'FastagID', 'Vehicle_Plate_Number']
        df = df.drop(columns=[col for col in drop_cols if col in df.columns], axis=1)

        st.write("Updated Dataset Preview (after dropping columns):")
        st.dataframe(df.head())

        # Missing values
        st.subheader("Missing Values in Each Column")
        st.write(df.isnull().sum())

        # Dtypes
        st.subheader("Column Data Types")
        st.write(df.dtypes)

        # Duplicate rows
        duplicate_rows = df.duplicated().sum()
        st.subheader("Duplicate Rows")
        st.write(f"Number of duplicate rows: {duplicate_rows}")

    else:
        st.info("Please upload a CSV or Excel file from the sidebar to get started.")

# --- Next Page ---
elif st.session_state["page"] == "next":
    st.title("üöÄ Data Pre-Processing")

    if st.button("‚¨ÖÔ∏è Back to Home"):
        st.session_state["page"] = "home"
        st.experimental_rerun()

import streamlit as st
import pandas as pd
import numpy as np

st.title("üìä Numerical Data Exploration & Outlier Treatment")

# Ensure 'df' exists
if 'df' not in st.session_state:
    st.warning("Dataset not found. Please upload your CSV/Excel file first.")
    st.stop()
else:
    df = st.session_state['df']

numerical_cols = df.select_dtypes(include='number').columns.tolist()
if 'isFraud' in numerical_cols:
    numerical_cols.remove('isFraud')

# --- Next Page button ---
st.subheader("Proceed to Next Stage")
if st.button("Go to Next Page ‚û°Ô∏è"):
    st.session_state["page"] = "next"
    st.session_state['df'] = df  # save dataframe for next page
    st.experimental_rerun()

# --- Histograms using Streamlit ---
st.subheader("Histograms for Numerical Columns (Original)")
if numerical_cols:
    for col in numerical_cols:
        st.write(f"Histogram of {col}")
        counts, bins = np.histogram(df[col], bins=30)
        hist_df = pd.DataFrame({'Bin': bins[:-1], 'Count': counts})
        st.bar_chart(hist_df.set_index('Bin')['Count'])
else:
    st.info("No numerical columns available for histograms.")

# --- Outlier Treatment ---
st.subheader("Outlier Treatment")
for col in ['Amount_paid', 'Vehicle_Speed']:
    if col in df.columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
        df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])

# --- Histograms after Outlier Treatment ---
st.subheader("Histograms after Outlier Treatment")
if numerical_cols:
    for col in numerical_cols:
        st.write(f"Histogram of {col} (Updated)")
        counts, bins = np.histogram(df[col], bins=30)
        hist_df = pd.DataFrame({'Bin': bins[:-1], 'Count': counts})
        st.bar_chart(hist_df.set_index('Bin')['Count'])
else:
    st.info("No numerical columns available for updated histograms.")

# --- Next Page button at bottom ---
if st.button("Go to Next Page ‚û°Ô∏è"):
    st.session_state["page"] = "next"
    st.session_state['df'] = df
    st.experimental_rerun()



# --- Next Page: Label Encoding & Timestamp Features ---
if st.session_state["page"] == "next":
    st.title("üõ† Data Preprocessing & Feature Engineering")
if 'df' in st.session_state:
  df = st.session_state['df']
  # --- Label Encoding ---
  st.subheader("Label Encoding Categorical Columns")
  from sklearn.preprocessing import LabelEncoder
  label_encoder = LabelEncoder()
  encode_cols = ["Fraud_indicator", "Lane_Type", "Vehicle_Dimensions",
                  "Vehicle_Type", "TollBoothID", "Geographical_Location"]
  for col in encode_cols:
      if col in df.columns:
          df[col] = label_encoder.fit_transform(df[col])
  st.success("Label encoding completed ‚úÖ")

  # --- Timestamp Feature Engineering ---
  st.subheader("Timestamp Feature Engineering")
  if 'Timestamp' in df.columns:
      df['Timestamp'] = pd.to_datetime(df['Timestamp'])
      df['Hour_of_Day'] = df['Timestamp'].dt.hour
      df['Day_of_Week'] = df['Timestamp'].dt.dayofweek
      df['Month'] = df['Timestamp'].dt.month
      st.write("New features created: Hour_of_Day, Day_of_Week, Month")
  else:
      st.info("No 'Timestamp' column found.")

  # Display updated dataset
  st.subheader("Updated Dataset Preview")
  st.dataframe(df.head())

  # Store back to session_state
  st.session_state['df'] = df

  # Back button
  if st.button("‚¨ÖÔ∏è Back to Home"):
      st.session_state["page"] = "home"
      st.experimental_rerun()
else:
  st.info("Dataset not found. Please upload your file on the Home page first.")

